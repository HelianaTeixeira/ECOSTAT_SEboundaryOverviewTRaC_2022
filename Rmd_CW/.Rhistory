library(here)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, dpi=300)
knitr::opts_chunk$set(cache=FALSE, fig.path="Figures/", cache.path="Cache/")
options(knitr.kable.NA = "")
options(digit=3)
source(here("R","MyFunctV2.R"))
#function to summarise QE (det) for records classed as High or Good
SumNG <- function(df,det){
summary(df[df$TwoClass=="GH",det])
}
#Get the data
Cat <- "Coastal" # water category, used in file  name for saving objects for subsequent use
FName.dat <-here("Data","dat.CWver2.csv")
dat.CW <- read.csv(file = FName.dat, header = TRUE)
# enter text for standard,labels for plotting, appendix section number etc
dec <- 2  # number of decimals to show
physChemText <- "Dissolved oxygen"
ylb <- "DO (mg/L)"
SectNum <- "A1.1.1"
#Legend numbers
fig_refA1 <- "Figure A1"
tab_refA1 <- "Table A1"
tab_refA2 <- "Table A2"
tab_refA3 <- "Table A3"
tab_refA4 <- "Table A4"
#Legend text for appendix
FCapA1 <- paste(fig_refA1,physChemText, "standards by country and broad type (single value black, minimum blue, maximum red), horizontal lines mark 25th and 75th quantiles for types with 2 or more countries contributing to the type.")
TCapA1 <- paste(tab_refA1,physChemText,"metrics used by country")
TCapA2 <- paste(tab_refA2,"records where",physChemText, "was reported as a value or a range")
TCapA3 <- paste(tab_refA3,"Number of different ",physChemText," standards by country and broad type")
TCapA4 <- paste(tab_refA4,"Overview of common types and number of MS/national types/distinct  ",physChemText," standards by country and broad type")
#Select standard
dat.u <- dat.CW %>%
filter(physChemText==physChemText,!is.na(ValueStd)) %>%
select(All.obs,GIG,MarineRegion,ICcode.TRAC,Country,RBD,NatType,physChemQECode,physChemQE,physChemText,physChemGMBoundary,SumMetric,ValueStd,ValueUpStd,UnitUsed,RangeRep,ReasonRange,Salinity1,Salinity2,DepthZone,MetricType) %>%
droplevels()
dim(dat.u)
# Check data, modify units if plot suggests issues
BPChk(dat.u)
# Check data, modify units if plot suggests issues
BPChk(dat.u)
# Check data, modify units if plot suggests issues
BPChk(dat.u)
# Check data, modify units if plot suggests issues
BPChk(dat.u)
# Check data, modify units if plot suggests issues
df<-dat.u
BPChk(df)
levels(dat.CW$physChemText)
#Get the data
Cat <- "Coastal" # water category, used in file  name for saving objects for subsequent use
FName.dat <-here("Data","dat.CWver2.csv")
dat.CW <- read.csv(file = FName.dat, header = TRUE)
# enter text for standard,labels for plotting, appendix section number etc
dec <- 2  # number of decimals to show
physChemText.u <- "Dissolved oxygen"
ylb <- "DO (mg/L)"
SectNum <- "A1.1.1"
#Legend numbers
fig_refA1 <- "Figure A1"
tab_refA1 <- "Table A1"
tab_refA2 <- "Table A2"
tab_refA3 <- "Table A3"
tab_refA4 <- "Table A4"
#Legend text for appendix
FCapA1 <- paste(fig_refA1,physChemText.u, "standards by country and broad type (single value black, minimum blue, maximum red), horizontal lines mark 25th and 75th quantiles for types with 2 or more countries contributing to the type.")
TCapA1 <- paste(tab_refA1,physChemText.u,"metrics used by country")
TCapA2 <- paste(tab_refA2,"records where",physChemText.u, "was reported as a value or a range")
TCapA3 <- paste(tab_refA3,"Number of different ",physChemText.u," standards by country and broad type")
TCapA4 <- paste(tab_refA4,"Overview of common types and number of MS/national types/distinct  ",physChemText.u," standards by country and broad type")
#Select standard
dat.u <- dat.CW %>%
filter(physChemText==physChemText.u,!is.na(ValueStd)) %>%
select(All.obs,GIG,MarineRegion,ICcode.TRAC,Country,RBD,NatType,physChemQECode,physChemQE,physChemText,physChemGMBoundary,SumMetric,ValueStd,ValueUpStd,UnitUsed,RangeRep,ReasonRange,Salinity1,Salinity2,DepthZone,MetricType) %>%
droplevels()
dim(dat.u)
# Check data, modify units if plot suggests issues
df<-dat.u
BPChk(df)
dat.u.m <- dat.u
dat.u <- dat.u.m
source(here("R","Prep_CWv5.R"))  # runs chunk of code to prepare the data
#Set up the plot symbols to match those in data set, use 19 for AA-EQS, 8 for 95th PC, 3 for median
count(dat.u.d,SumMetric)
#Edit the next line
symb <- c(5,3,8,19,18,12,17,2)
if(length(symb)!=dim(count(dat.u.d,SumMetric))[1])stop("Edit symb, it is wrong length")
# Chunk to calculate summary statistics
# Use the  "distinct" boundary values (dat.u.d) to avoid weighting values where countries apply identical type specific values in multiple RBDs (or NatTypes).
# Select data with summary statistics that are a measure of central tendency
SumDat <- dat.u.d %>%
filter(SumMetric=="AA-EQS"|
SumMetric == "Median"|
SumMetric == "AGM_int_c"|
SumMetric == "winter"|
SumMetric == "spring"|
SumMetric == "growth season mean"|
SumMetric == "summer"|
SumMetric == "autumn")
#Create long format to simplify calculating quantiles and for analysis of variance by putting both ValueStd and ValueUpStd into single variable "Value".
SumDat.l <- pivot_longer(dat.u.d,cols = starts_with("Val"),names_to = "col",values_to = "Value" )
SumDat.l <- left_join(SumDat.l,CntryInGroup) # join the number of countries in the group for subsequent filter
#calculate quantiles for the MS boundary values
qA10 <-quantile(SumDat.l$Value,0.1,na.rm = TRUE)
qA25 <- quantile(SumDat.l$Value,0.25,na.rm = TRUE)
qA50 <- quantile(SumDat.l$Value,0.5,na.rm = TRUE)
qA75 <- quantile(SumDat.l$Value,0.75,na.rm = TRUE)
qA90 <- quantile(SumDat.l$Value,0.9,na.rm = TRUE)
min.x <- min(c(dat.u$ValueStd,dat.u$ValueUpSt), na.rm=TRUE)
max.x <- max(c(dat.u$ValueStd,dat.u$ValueUpSt), na.rm=TRUE)
SumDat.l <- SumDat.l %>% filter(!is.na(Value),ICcode.TRAC !="inapplicable")# remove groups not needed
#Calculate the full IC type specific quantiles
q25 <- aggregate(SumDat.l$Value,0.25, by=list(SumDat.l$ICcode.TRAC), FUN=quantile, p=.25,na.rm = TRUE)
q75 <- aggregate(SumDat.l$Value, by=list(SumDat.l$ICcode.TRAC), FUN=quantile, p=.75,na.rm = TRUE)
Q <- data.frame(q25,q75[2])
Q <- Q %>% rename(ICcode.TRAC = Group.1, q25 = x,q75 = x.1)
#join quantiles to dataframe containing number of countries in each group
GrpGT2.Q <- full_join(NinGroup,Q)
GrpGT2.Q <- GrpGT2.Q %>% mutate(q25u = ifelse(n>2,q25,NA))%>% mutate(q75u = ifelse(n>2,q75,NA))
#Calculate the marine region specific quantiles
q25 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.25,na.rm = TRUE)
q75 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.75,na.rm = TRUE)
q50 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.5,na.rm = TRUE)
q90 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.9,na.rm = TRUE)
Q <- data.frame(q25,q75[2],q50[2],q90[2])
Q <- Q %>% rename(MarineRegion = Group.1, q25 = x,q75 = x.1,q50 = x.2,q90 = x.3)
#join agg quantiles to dataframe containing number of countries in each group
AggGrpGT2.Q <- full_join(NinAggGroup,Q)
AggGrpGT2.Q <- AggGrpGT2.Q %>% mutate(q25u = ifelse(n>2,q25,NA))%>% mutate(q75u = ifelse(n>2,q75,NA))%>% mutate(q90u = ifelse(n>2,q90,NA))%>% mutate(q50u = ifelse(n>2,q50,NA))
source(here("R","Prep_CWv5.R"))  # runs chunk of code to prepare the data
#Set up the plot symbols to match those in data set, use
#8 for 95th PC, 4 90th PC, 6 max
#19 AA-EQS, 17 median, 7 summer, 12 spring, 10 winter, 13 autumn, 14 growth
#5 5th PC, 9 10th PC, 2 min
count(dat.u.d,SumMetric)
#Edit the next line
symb <- c(9,5,19,2,7)#5,3,8,19,18,12,17,2
if(length(symb)!=dim(count(dat.u.d,SumMetric))[1])stop("Edit symb, it is wrong length")
SumDat <- dat.u.d %>%
filter(SumMetric=="AA-EQS"|
SumMetric == "Median"|
SumMetric == "AGM_int_c"|
SumMetric == "winter"|
SumMetric == "spring"|
SumMetric == "growth season mean"|
SumMetric == "summer"|
SumMetric == "autumn")
#Create long format to simplify calculating quantiles and for analysis of variance by putting both ValueStd and ValueUpStd into single variable "Value".
SumDat.l <- pivot_longer(dat.u.d,cols = starts_with("Val"),names_to = "col",values_to = "Value" )
SumDat.l <- left_join(SumDat.l,CntryInGroup) # join the number of countries in the group for subsequent filter
#calculate quantiles for the MS boundary values
qA10 <-quantile(SumDat.l$Value,0.1,na.rm = TRUE)
qA25 <- quantile(SumDat.l$Value,0.25,na.rm = TRUE)
qA50 <- quantile(SumDat.l$Value,0.5,na.rm = TRUE)
qA75 <- quantile(SumDat.l$Value,0.75,na.rm = TRUE)
qA90 <- quantile(SumDat.l$Value,0.9,na.rm = TRUE)
min.x <- min(c(dat.u$ValueStd,dat.u$ValueUpSt), na.rm=TRUE)
max.x <- max(c(dat.u$ValueStd,dat.u$ValueUpSt), na.rm=TRUE)
SumDat.l <- SumDat.l %>% filter(!is.na(Value),ICcode.TRAC !="inapplicable")# remove groups not needed
#Calculate the full IC type specific quantiles
q25 <- aggregate(SumDat.l$Value,0.25, by=list(SumDat.l$ICcode.TRAC), FUN=quantile, p=.25,na.rm = TRUE)
q75 <- aggregate(SumDat.l$Value, by=list(SumDat.l$ICcode.TRAC), FUN=quantile, p=.75,na.rm = TRUE)
Q <- data.frame(q25,q75[2])
Q <- Q %>% rename(ICcode.TRAC = Group.1, q25 = x,q75 = x.1)
#join quantiles to dataframe containing number of countries in each group
GrpGT2.Q <- full_join(NinGroup,Q)
GrpGT2.Q <- GrpGT2.Q %>% mutate(q25u = ifelse(n>2,q25,NA))%>% mutate(q75u = ifelse(n>2,q75,NA))
#Calculate the marine region specific quantiles
q25 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.25,na.rm = TRUE)
q75 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.75,na.rm = TRUE)
q50 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.5,na.rm = TRUE)
q90 <- aggregate(SumDat.l$Value, by=list(SumDat.l$MarineRegion), FUN=quantile, p=.9,na.rm = TRUE)
Q <- data.frame(q25,q75[2],q50[2],q90[2])
Q <- Q %>% rename(MarineRegion = Group.1, q25 = x,q75 = x.1,q50 = x.2,q90 = x.3)
#join agg quantiles to dataframe containing number of countries in each group
AggGrpGT2.Q <- full_join(NinAggGroup,Q)
AggGrpGT2.Q <- AggGrpGT2.Q %>% mutate(q25u = ifelse(n>2,q25,NA))%>% mutate(q75u = ifelse(n>2,q75,NA))%>% mutate(q90u = ifelse(n>2,q90,NA))%>% mutate(q50u = ifelse(n>2,q50,NA))
#Dot plots of "ValueStd" & "ValueUpStd" by "Country"
P1 <- DP() +
geom_hline(yintercept = c(qA50,qA25,qA10),linetype="dashed", color=c("blue","orange","red"))
#Dot plot of "ValueStd" & "ValueUpStd" by "ICcode.TRAC" (IC types)
P2 <- DP2()+   theme(axis.text.x = element_text(angle = 90,hjust=0.5,vjust=0.5)) +
geom_segment(data=GrpGT2.Q,mapping=aes(x=seq(0.75,dim(GrpGT2.Q)[1]-0.25,1.0),y=q25u,xend=seq(1.25,dim(GrpGT2.Q)[1]+0.25,1.0),yend=q25u),inherit.aes = FALSE,colour = "green",size = 1.5)+
geom_segment(data=GrpGT2.Q,mapping=aes(x=seq(0.75,dim(GrpGT2.Q)[1]-0.25,1.0),y=q75u,xend=seq(1.25,dim(GrpGT2.Q)[1]+0.25,1.0),yend=q75u),inherit.aes = FALSE,colour = "red",size = 1.5)
#Dot plots of "ValueStd" & "ValueUpStd" by "Country" & "ICcode.TRAC" (IC types)
# start by plotting the value upper in red
ggplot(dat.u.d, aes(x=Country, y=ValueUpStd,shape=SumMetric))+
geom_point(color="red",position = position_nudge(x= -0.1 ,y = 0))+
scale_shape_manual(values=symb,name  ="") +
# add lower point of range as blue symbol
geom_point(data = subset(dat.u.d,!is.na(ValueUpStd)), mapping =
aes(x = Country, y = ValueStd, shape = SumMetric),color="blue",position = position_nudge(x=0.1 ,y = 0))+
ylab(ylb)+xlab("")+
facet_wrap(~ ICcode.TRAC,ncol=2,nrow=8) +
theme_bw() +
theme(axis.text.x = element_text(angle = 90,hjust=0.5,vjust=0.5))+
theme(legend.position = "bottom",
legend.text = element_text(color = "black")) +
# Add the values (exclude those which were a range), this needs to  be done last to avoid the legend points being colored
geom_point(data = subset(dat.u.d,is.na(ValueUpStd)), mapping =
aes(x = Country, y = ValueStd, shape = SumMetric),color="black")+
geom_hline(data=GrpGT2.Q,mapping = aes(yintercept = q25u ),colour = "green",linetype = "dashed")+
geom_hline(data=GrpGT2.Q,mapping = aes(yintercept = q75u ),colour = "red",linetype = "dashed")
Metrics%>% kable(format="pandoc",cap=TCapA1)
Temp %>% kable(format="pandoc",cap=TCapA2)
Temp %>% kable(format="pandoc",cap=TCapA2)
addmargins(table(dat.u.d$ICcode.TRAC,dat.u.d$Country)) %>% kable(format="pandoc",cap=TCapA3)
#Save the objects needed for tables and figures for subsequent use
OutFile <- here("Data",paste0(Cat,physChemText.u,".RData"))
save(dat.u.d,Metrics,Temp,Temp1,Temp2,OverV4,RangeCntry,ValCntry,TypeAllCntry,NinGroup,CntryInGroup,GrpGT2,symb,ylb,dec,physChemText.u,dat.u.d, dat.u,SumDat.l,qA10,qA25,qA50,qA75,qA90,min.x,max.x,GrpGT2.Q,AggGrpGT2.Q,P1,P2,file=OutFile)
OverV4%>% kable(format="pandoc",cap=TCapA4)
addmargins(table(dat.u.d$ICcode.TRAC,dat.u.d$Country)) %>% kable(format="pandoc",cap=TCapA3)
OverV4%>% kable(format="pandoc",cap=TCapA4)
# Chunk 1
rm(list = ls())
library(dplyr )
library(ggplot2)
library(tidyr)
library(knitr)
library(here)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, dpi=300)
knitr::opts_chunk$set(cache=FALSE, fig.path="Figures/", cache.path="Cache/")
options(knitr.kable.NA = "")
options(digit=3)
source(here("R","MyFunctV2.R"))
# Chunk 2
#Get the data
Cat <- "Coastal" # water category, used in file  name for saving objects for subsequent use
FName.dat <-here("Data","dat.CWver2.csv")
dat.CW <- read.csv(file = FName.dat, header = TRUE)
# Chunk 3
# enter text for standard,labels for plotting, appendix section number etc
dec <- 1  # number of decimals to show
physChemText.u <- "% oxygen saturation"
ylb <- "% saturation GM boundary"
SectNum <- "A1.1.2"
#Legend labels
fig_refA1 <- "Figure A6"
fig_refA2 <- "Figure A7"
tab_refA1 <- "Table A5"
tab_refA2 <- "Table A6"
tab_refA3 <- "Table A7"
tab_refA4 <- "Table A8"
fig_refA2 <- "Figure A8"
fig_refA3 <- "Figure A9"
fig_refA4 <- "Figure A10"
fig_refA5 <- "Figure A11"
fig_refA6 <- "Figure A12"
#Legend text for appendix
FCapA1 <- paste(fig_refA1,physChemText.u, "standards by country and IC type (single value black, minimum blue, maximum red). Horizontal dotted lines show the median values for the uppder (red) and lower (blue) groups of standards")
FCapA2 <- paste(fig_refA2,physChemText.u, "standards by country and GIG (single value black, minimum blue, maximum red). Horizontal dotted lines show the median values for the uppder (red) and lower (blue) groups of standards")
TCapA1 <- paste(tab_refA1,physChemText.u,"metrics used by country")
TCapA2 <- paste(tab_refA2,"records where",physChemText.u, "was reported as a value or a range")
TCapA3 <- paste(tab_refA3,"Number of different ",physChemText.u," standards by country and IC type")
TCapA4 <- paste(tab_refA4,"Overview of common types and number of MS/national types/distinct  ",physChemText.u," standards by country and IC type")
FCapA3 <- paste(fig_refA3,"Coastal",physChemText.u,"standards coplots showing the range of ",physChemText.u," concentration along the salinity gradient for each Intercalibration Common Type (IC), standards colored by Country.")
FCapA4 <- paste(fig_refA4,"Coastal",physChemText.u,"standards coplots showing the range of ",physChemText.u," concentration along the salinity gradient for each Marine Region, standards colored by IC Type.")
FCapA5 <- paste(fig_refA5,"Coastal",physChemText.u,"standards coplots showing the range of ",physChemText.u," concentration along the salinity gradient for each Geographical Intercalibration Group (GIG), standards colored by Marine Region.")
FCapA6 <- paste(fig_refA6,"Coastal",physChemText.u,"standards coplots showing the range of ",physChemText.u," concentration along the salinity gradient for each Geographical Intercalibration Group (GIG), standards colored by Intercalibration Common Type (IC).")
#Select standard
dat.u <- dat.CW %>%
filter(physChemText==physChemText.u,!is.na(ValueStd)) %>%
select(All.obs,GIG,MarineRegion,ICcode.TRAC,Country,RBD,NatType,physChemQECode,physChemQE,physChemText,physChemGMBoundary,SumMetric,ValueStd,ValueUpStd,UnitUsed,RangeRep,ReasonRange,Salinity1,Salinity2,DepthZone,MetricType,ICType) %>%
droplevels()
dim(dat.u)
# Chunk 4: CheckDataPlot
# Check data, modify units if plot suggests issues
df<-dat.u
BPChk(df)
# Chunk 5
dat.u.m <- dat.u%>%
mutate (ValueUpStd=case_when(
Country=="HR" & ValueStd==40 ~ 150,
TRUE ~ as.numeric(ValueUpStd)))%>%
mutate(RangeRep=case_when(
Country=="HR" & ValueUpStd==150 ~ "TRUE",
TRUE ~ as.character(RangeRep))) %>%
mutate(ReasonRange=case_when(
Country=="HR" & ValueUpStd==150 ~ "High low",
TRUE ~ as.character(ReasonRange))) #Croatia is range: associate upper & lower range in one row, set range to TRUE and reason range to High-low
#drop unused row All.obs!=458
dat.u <- filter(dat.u.m, All.obs!=8652)
# Chunk 6
source(here("R","Prep_CWv5.R"))  # runs chunk of code to prepare the data
# Chunk 7
datL.u.d <- pivot_longer(dat.u.d,cols = starts_with("Val"),names_to = "col",values_to = "Value" )
datL.u.d <- datL.u.d %>% filter(!is.na(Value)) %>%
mutate(Range = ifelse(col=="ValueStd","L","U")) %>%
mutate(physChemStandard2.u=SumMetric)
#Set up the plot symbols to match those in data set, use
#8 for 95th PC, 4 90th PC, 6 max
#19 AA-EQS, 17 median, 7 summer, 12 spring, 10 winter, 13 autumn, 14 growth
#5 5th PC, 9 10th PC, 2 min
count(datL.u.d,physChemStandard2.u)
#Edit the next line
symb <- c(8,19,17,10)
if(length(symb)!=dim(count(datL.u.d,physChemStandard2.u))[1])stop("Edit symb, it is wrong length")
# Chunk 8
qA25 <- quantile(datL.u.d$Value,0.25,na.rm=T)
qA50 <- quantile(datL.u.d$Value,0.5,na.rm=T)
qA75 <- quantile(datL.u.d$Value,0.75,na.rm=T)
qA90 <- quantile(datL.u.d$Value,0.90,na.rm=T)
min.x <- min(datL.u.d$Value, na.rm=TRUE)
max.x <- max(datL.u.d$Value, na.rm=TRUE)
qA10U <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"),0.1,na.rm = TRUE)
qA25U <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"),0.25,na.rm = TRUE)
qA50U <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"),0.5,na.rm = TRUE)
qA75U <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"),0.75,na.rm = TRUE)
qA90U <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"),0.90,na.rm = TRUE)
qA10L <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"),0.1,na.rm = TRUE)
qA25L <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"),0.25,na.rm = TRUE)
qA50L <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"),0.5,na.rm = TRUE)
qA75L <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"),0.75,na.rm = TRUE)
qA90L <- quantile(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"),0.90,na.rm = TRUE)
#Calculate the full IC type specific quantiles
q25U <- aggregate(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"), by=list(subset(datL.u.d$ICcode.TRAC,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile")), FUN=quantile, p=.25,na.rm = TRUE)
q50U <- aggregate(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"), by=list(subset(datL.u.d$ICcode.TRAC,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile")), FUN=quantile, p=.5,na.rm = TRUE)
q75U <- aggregate(subset(datL.u.d$Value,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile"), by=list(subset(datL.u.d$ICcode.TRAC,datL.u.d$Range=="U" & datL.u.d$physChemStandard2.u != "10th percentile")), FUN=quantile, p=.75,na.rm = TRUE)
q25L <- aggregate(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"), by=list(subset(datL.u.d$ICcode.TRAC,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile")), FUN=quantile, p=.25,na.rm = TRUE)
q50L <- aggregate(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"), by=list(subset(datL.u.d$ICcode.TRAC,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile")), FUN=quantile, p=.5,na.rm = TRUE)
q75L <- aggregate(subset(datL.u.d$Value,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile"), by=list(subset(datL.u.d$ICcode.TRAC,datL.u.d$Range=="L" & datL.u.d$physChemStandard2.u != "90th percentile")), FUN=quantile, p=.75,na.rm = TRUE)
GrpGT2.Q <- datL.u.d %>% select(ICcode.TRAC) %>% distinct() %>% arrange(ICcode.TRAC)
GrpGT2.Q <- left_join(GrpGT2.Q,NinGroup)
GrpGT2.Q <- left_join(GrpGT2.Q,q25L, by= c("ICcode.TRAC"="Group.1")) %>% rename(q25L=x)
GrpGT2.Q <- left_join(GrpGT2.Q,q50L, by= c("ICcode.TRAC"="Group.1")) %>% rename(q50L=x)
GrpGT2.Q <- left_join(GrpGT2.Q,q75L, by= c("ICcode.TRAC"="Group.1")) %>% rename(q75L=x)
GrpGT2.Q <- left_join(GrpGT2.Q,q25U, by= c("ICcode.TRAC"="Group.1")) %>% rename(q25U=x)
GrpGT2.Q <- left_join(GrpGT2.Q,q50U, by= c("ICcode.TRAC"="Group.1")) %>% rename(q50U=x)
GrpGT2.Q <- left_join(GrpGT2.Q,q75U, by= c("ICcode.TRAC"="Group.1")) %>% rename(q75U=x)
GrpGT2.Q <- GrpGT2.Q %>%
mutate(q25Lu = ifelse(n>2,q25L,NA)) %>%
mutate(q50Lu = ifelse(n>2,q50L,NA)) %>%
mutate(q75Lu = ifelse(n>2,q75L,NA)) %>%
mutate(q25Uu = ifelse(n>2,q25U,NA)) %>%
mutate(q50Uu = ifelse(n>2,q50U,NA)) %>%
mutate(q75Uu = ifelse(n>2,q75U,NA))
# Chunk 9: salinity gradient
# #Create long format by putting both ValueStd and ValueUpStd into single var "Value" and match correspondent salinities into single var "Salinity", for analysis of variance and coplots, incl. all summary metrics (central tendency, quantiles and other)
# dat.shrt <- dat.u%>%
#   select(All.obs,GIG,MarineRegion,ICcode.TRAC,Country,NatType,physChemText,SumMetric,ValueStd,ValueUpStd,UnitUsed,RangeRep,ReasonRange,DepthZone,MetricType)%>%
#   droplevels()
# dim(dat.shrt)
#
# dat.shrt.l <- pivot_longer(dat.shrt,cols = starts_with("Val"),names_to = "col",values_to = "Value" )
#
# #add Salinity to correspondent Value
# salinities <- select(dat.u, c("All.obs","Salinity1","Salinity2"))
# dat.shrt.l <- left_join(dat.shrt.l,salinities, by = "All.obs")
# dat.shrt.l$Salinity2<-(as.numeric(dat.shrt.l$Salinity2))
# dat.shrt.l <- dat.shrt.l%>% mutate(Salinity = case_when(col=="ValueStd" ~ Salinity1,
#                                                       col=="ValueUpStd" ~ Salinity2))
#
#coplots with all QE vs salinity where available
coP1<- coPIC()
coP2<- coPMaReg()
coP3<- coPGIG.MR()
coP4<- coPGIG.IC()
# Chunk 10
#Dot plots of "ValueStd" & "ValueUpStd" by "Country"
P1 <- ggplot(subset(datL.u.d,RangeRep==TRUE), aes(x=Country, y=Value,color=Range,shape=physChemStandard2.u))+
geom_point(position = position_nudge(x= +0.1 ,y = 0))+
scale_shape_manual(values = symb, name ="")+
scale_color_manual(values = c("blue","red"))+
ylab(ylb)+xlab("")+
theme_bw() +
geom_point(data = subset(datL.u.d,RangeRep==FALSE), mapping =
aes(x = Country, y = Value, shape = physChemStandard2.u),color="black",position = position_nudge(x= -0.1 ,y = 0))+
theme(legend.position = "bottom",
legend.text = element_text(color = "black"))+
geom_hline(yintercept = qA50U ,colour = "red",linetype = "dashed")+
geom_hline(yintercept = qA50L ,colour = "blue",linetype = "dashed")
# Chunk 11
#Dot plot of "ValueStd" & "ValueUpStd" by "ICcode.TRAC" (IC types)
P2 <- ggplot(datL.u.d, aes(x=ICcode.TRAC, y=Value,color=Range,shape=physChemStandard2.u))+
geom_point()+
scale_shape_manual(values = symb, name ="")+
scale_color_manual(values = c("blue","red"))+
ylab(ylb)+xlab("")+
theme_bw() +
theme(legend.position = "bottom",
legend.text = element_text(color = "black"))+
theme(axis.text.x = element_text(angle = 90,hjust=0.5,vjust=0.5))+
geom_segment(data=GrpGT2.Q,mapping=aes(x=seq(0.75,dim(GrpGT2.Q)[1]-0.25,1.0),y=q25Uu,xend=seq(1.25,dim(GrpGT2.Q)[1]+0.25,1.0),yend=q25Uu),inherit.aes = FALSE,colour = "green",size = 1.0)+
geom_segment(data=GrpGT2.Q,mapping=aes(x=seq(0.75,dim(GrpGT2.Q)[1]-0.25,1.0),y=q75Uu,xend=seq(1.25,dim(GrpGT2.Q)[1]+0.25,1.0),yend=q75Uu),inherit.aes = FALSE,colour = "red",size = 1.0)+
geom_segment(data=GrpGT2.Q,mapping=aes(x=seq(0.75,dim(GrpGT2.Q)[1]-0.25,1.0),y=q25Lu,xend=seq(1.25,dim(GrpGT2.Q)[1]+0.25,1.0),yend=q25Lu),inherit.aes = FALSE,colour = "green",size = 1.0)+
geom_segment(data=GrpGT2.Q,mapping=aes(x=seq(0.75,dim(GrpGT2.Q)[1]-0.25,1.0),y=q75Lu,xend=seq(1.25,dim(GrpGT2.Q)[1]+0.25,1.0),yend=q75Lu),inherit.aes = FALSE,colour = "red",size = 1.0)
# Chunk 12
#Dot plots of "ValueStd" & "ValueUpStd" by "Country" & "ICcode.TRAC" (IC types)
ggplot(subset(datL.u.d,RangeRep==TRUE), aes(x=Country, y=Value,color=Range,shape=physChemStandard2.u))+
geom_point(position = position_nudge(x= +0.1 ,y = 0))+
scale_shape_manual(values = symb, name ="")+
scale_color_manual(values = c("blue","red"))+
ylab(ylb)+xlab("")+
theme_bw() +
geom_point(data = subset(datL.u.d,RangeRep==FALSE), mapping =
aes(x = Country, y = Value, shape = physChemStandard2.u),color="black",position = position_nudge(x= -0.1 ,y = 0))+
theme(legend.position = "bottom",
legend.text = element_text(color = "black")) +
facet_wrap(~ ICcode.TRAC,ncol=3,nrow=8)+
theme(axis.text.x = element_text(angle = 90,hjust=0.5,vjust=0.5))+
geom_hline(data=GrpGT2.Q,mapping = aes(yintercept = q50Lu ),colour = "blue",linetype = "dashed")+
geom_hline(data=GrpGT2.Q,mapping = aes(yintercept = q50Uu ),colour = "red",linetype = "dashed")
# Chunk 13
#Dot plots of "ValueStd" & "ValueUpStd" by "Country" & "GIG"
ggplot(subset(datL.u.d,RangeRep==TRUE), aes(x=Country, y=Value,color=Range,shape=physChemStandard2.u))+
geom_point(position = position_nudge(x= +0.1 ,y = 0))+
scale_shape_manual(values = symb, name ="")+
scale_color_manual(values = c("blue","red"))+
ylab(ylb)+xlab("")+
theme_bw() +
geom_point(data = subset(datL.u.d,RangeRep==FALSE), mapping =
aes(x = Country, y = Value, shape = physChemStandard2.u),color="black",position = position_nudge(x= -0.1 ,y = 0))+
theme(legend.position = "bottom",
legend.text = element_text(color = "black")) +
facet_wrap(~ GIG,scale="free_x",ncol=4,nrow=1)+
theme(axis.text.x = element_text(angle = 90,hjust=0.5,vjust=0.5))+
geom_hline(yintercept = qA50U ,colour = "red",linetype = "dashed")+
geom_hline(yintercept = qA50L ,colour = "blue",linetype = "dashed")
# Chunk 14
Metrics%>% kable(format="pandoc",cap=TCapA1)
# Chunk 15
Temp %>% kable(format="pandoc",cap=TCapA2)
# Chunk 16
addmargins(table(dat.u.d$ICcode.TRAC,dat.u.d$Country)) %>% kable(format="pandoc",cap=TCapA3)
# Chunk 18
coP1
# Chunk 19
coP2
# Chunk 20
coP3
# Chunk 21
coP4
# Chunk 22
#Save the objects needed for tables and figures for subsequent use
OutFile <- here("Data",paste0(Cat,physChemText.u,".RData"))
save(dat.u.d,Metrics,Temp,Temp1,Temp2,OverV4,RangeCntry,ValCntry,TypeAllCntry,NinGroup,CntryInGroup,GrpGT2,symb,ylb,dec,physChemText.u,dat.u.d,dat.u,datL.u.d,qA25,qA50,qA75,qA90,min.x,max.x,qA10U,qA25U,qA50U,qA75U,qA90U,qA10L,qA25L,qA50L,qA75L,qA90L,GrpGT2.Q,P1,P2,coP1,coP2,coP3,coP4,file=OutFile)
#not saved here (GrpGT2.Q,AggGrpGT2.Q,dat.shrt.l)
# Chunk 1
rm(list = ls())
library(dplyr )
library(ggplot2)
library(tidyr)
library(knitr)
library(readxl)
library(stringr)# needed for mutate of EEA data set
library(gridExtra)
library(car) # for anova
library(sjstats) # for effect sizes
library(here)
library(kableExtra)
source(here("R","MyFunctV2.R"))
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, dpi=300)
knitr::opts_chunk$set(cache=FALSE, fig.path="Figures/", cache.path="Cache/")
options(knitr.kable.NA = "")
options(digit=3)
# Chunk 2
load(here("Data","Coastal% oxygen saturation.RData"))
SectNum <- "3.1.1.2"
#add legends
#labels for legends
fig_ref1 <- "Figure 3.3"
fig_ref2 <- "Figure 3.4"
# fig_ref3 <- "Figure 3.5"
tab_ref1 <- "Table 3.3"
tab_ref2 <- "Table 3.4"
#---------------------------------------------------------------------------------------------------------
#Legends for report
FCap1 <- paste(fig_ref1,"Comparison of coastal",physChemText.u,"standards by country. (single value black, minimum blue, maximum red symbols, dotted lines show median values for the upper (red) and lower (blue) groups.")
FCap2 <- paste(fig_ref2,"Coastal",physChemText.u,"standards  by IC type (single value black, minimum blue, maximum red, Horizontal lines mark the 25th (green) and 75th (red) quantiles for each group of standards.)")
# FCap3 <- paste(fig_ref3,"Coastal",physChemText.u,"standards' coplots showing the range of ",physChemText.u," concentration along the salinity gradient in each Geographical Intercalibration Group (GIG), standards colored by common Intercalibration Type (IC).")
TCap1 <- paste(tab_ref1,"Analysis of variance for factorial model relating country to member state boundary values for lower and upper groups of log ",physChemText.u, " boundaries (Including main and partial effect sizes,Omega squared.")
TCap2 <- paste(tab_ref2,"Overview of common types showing the number of countires/national types/distinct standards for coastal", physChemText.u,".")
# Chunk 3
#Chunk to test differences between types and country
datL.u.d <- datL.u.d
datL.u.d <- left_join(datL.u.d,CntryInGroup) # join the number of countries in the group for subsequent filter
# test homogeneity of variance, select appropriate model
leveneTest(Value ~ Country, data=datL.u.d,subset = n>2 )# dropped "ICcode.TRAC"
leveneTest(log(Value) ~ Country, data=datL.u.d,subset = n>2 )# dropped "ICcode.TRAC"
# create factorial model using only IC types with more than 2 countries in the group (dropped "ICcode.TRAC")
mod.L <- aov(log(Value) ~ Country, data=datL.u.d,subset =  Range =="L")
mod.U <- aov(log(Value) ~ Country, data=datL.u.d,subset = Range =="U")
# look at residuals
r = residuals(mod.L, type="response")
Shap.test.L <- shapiro.test(r) # test for normality of residuals
# look at residuals
r = residuals(mod.U, type="response")
Shap.test.U <- shapiro.test(r) # test for normality of residuals
my_anova.L <- Anova(mod.L, type="III") # with car package use type III sum squares as unbalanced design
Om_sq.L <- omega_sq(my_anova.L,partial = FALSE) # determine the effect size (proportion of variance explained by each factor)
pOm_sq.L <- omega_sq(my_anova.L,partial = TRUE) # determine the partial effect size (proportion of variance explained by each factor after excluding the variance explained by other predictors)  omega_sq corrects for small sample size
Table.L <- my_anova.L %>% mutate(term = c("Intercept","Country","Residuals")) # dropped "ICcode.TRAC"
Table.L <- left_join(Table.L,Om_sq.L)
Table.L <- left_join(Table.L,pOm_sq.L)
my_anova.U <- Anova(mod.U, type="III") # with car package use type III sum squares as unbalanced design
Om_sq.U <- omega_sq(my_anova.U,partial = FALSE) # determine the effect size (proportion of variance explained by each factor)
pOm_sq.U <- omega_sq(my_anova.U,partial = TRUE) # determine the partial effect size (proportion of variance explained by each factor after excluding the variance explained by other predictors)  omega_sq corrects for small sample size
Table.U <- my_anova.U %>% mutate(term = c("Intercept","Country","Residuals"))# dropped "ICcode.TRAC"
Table.U <- left_join(Table.U,Om_sq.U)
Table.U <- left_join(Table.U,pOm_sq.U)
Table <- Table.L
Table <- rbind(Table,Table.U)
# Chunk 4
#Dot plots of "ValueStd" & "ValueUpStd" by "Country"
P1
# Chunk 5
P2
# Chunk 6
kable(Table.L[c(5,6,7,1:4)],col.names = c("","Omega sq,","p Omega sq","Sum sq","Df","F val","Pr"),digits = c(2,2,2,1,2,2,3),format = "pandoc",caption ="Lower Boundaries",label = NULL)
kable(Table.U[c(5,6,7,1:4)],col.names = c("","Omega sq,","p Omega sq","Sum sq","Df","F val","Pr"),digits = c(2,2,2,1,2,2,3),format = "pandoc",caption = "Upper Boundaries",label = NULL)
# Chunk 7
OverV4%>% kable(format="pandoc",cap="")
